import os
import requests
import zipfile
import pandas as pd
import glob

import base64
import json

# ä½ çš„åŸå¸‚å°ç…§è¡¨å’Œ classify_building_age å‡½å¼ä¿æŒä¸è®Š
city_code_map = {
    "a": "å°åŒ—å¸‚", "b": "å°ä¸­å¸‚", "c": "åŸºéš†å¸‚", "d": "å°å—å¸‚", "e": "é«˜é›„å¸‚",
    "f": "æ–°åŒ—å¸‚", "g": "å®œè˜­ç¸£", "h": "æ¡ƒåœ’å¸‚", "i": "å˜‰ç¾©å¸‚", "j": "æ–°ç«¹ç¸£",
    "k": "è‹—æ —ç¸£", "m": "å—æŠ•ç¸£", "n": "å½°åŒ–ç¸£", "o": "æ–°ç«¹å¸‚",
    "p": "é›²æ—ç¸£", "q": "å˜‰ç¾©ç¸£", "t": "å±æ±ç¸£",
    "u": "èŠ±è“®ç¸£", "v": "å°æ±ç¸£", "w": "é‡‘é–€ç¸£", "x": "æ¾æ¹–ç¸£", "z": "é€£æ±Ÿç¸£"
}

def classify_building_age(age):
    if pd.isna(age):
        return None
    age = float(age)
    if age == 0:
        return "é å”®å±‹"
    elif 0 < age <= 5:
        return "æ–°æˆå±‹"
    else:
        return "ä¸­å¤å±‹"

def season_code_to_chinese_quarter(season_code):
    if len(season_code) == 5 and season_code[3] == 'S':
        year = season_code[:3]
        quarter_map = {'1': 'ç¬¬ä¸€å­£', '2': 'ç¬¬äºŒå­£', '3': 'ç¬¬ä¸‰å­£', '4': 'ç¬¬å››å­£'}
        quarter = quarter_map.get(season_code[-1], 'æœªçŸ¥å­£åº¦')
        return f"{year}å¹´{quarter}"
    return "æœªçŸ¥å­£åº¦"

def convert_season_code_input(season_code: str) -> str:
    # å°‡ 11401 -> 114S1 çš„æ ¼å¼
    if len(season_code) == 5 and season_code.isdigit():
        year = season_code[:3]
        quarter = season_code[3:]
        if quarter in ['01', '02', '03', '04']:
            return f"{year}S{int(quarter)}"
    return season_code  # è‹¥å·²æ˜¯æ­£ç¢ºæ ¼å¼æˆ–æ ¼å¼ä¸ç¬¦å‰‡ä¸è®Šå‹•


def convert_season_code_for_export(season_code: str) -> str:
    """
    å°‡ S æ ¼å¼è½‰æ›ç‚º 0 æ ¼å¼ï¼Œç”¨æ–¼æª”å
    ä¾‹å¦‚ï¼š114S1 -> 11401, 114S2 -> 11402
    """
    if len(season_code) == 5 and season_code[3] == 'S':
        year = season_code[:3]
        quarter = season_code[-1]
        return f"{year}0{quarter}"
    return season_code

def github_push_file(repo_owner, repo_name, branch, file_path, commit_message, github_token):
    """
    å°‡æœ¬åœ°æª”æ¡ˆæ¨é€ï¼ˆæ–°å¢æˆ–æ›´æ–°ï¼‰åˆ° GitHub repoã€‚
    
    åƒæ•¸:
    - repo_owner: GitHub æ“æœ‰è€…å¸³è™Ÿæˆ–çµ„ç¹”å
    - repo_name: å€‰åº«å
    - branch: è¦æ¨é€çš„åˆ†æ”¯åç¨±
    - file_path: æœ¬åœ°æª”æ¡ˆè·¯å¾‘
    - commit_message: Commit è¨Šæ¯
    - github_token: GitHub Personal Access Token
    """
    # ç›®æ¨™ repo çš„ API URL è·¯å¾‘
    api_url = f"https://api.github.com/repos/{repo_owner}/{repo_name}/contents/{os.path.basename(file_path)}"
    
    # å…ˆå–å¾—è©²æª”æ¡ˆæ˜¯å¦å·²å­˜åœ¨(æ‹¿ SHA)
    headers = {
        "Authorization": f"token {github_token}",
        "Accept": "application/vnd.github+json"
    }
    
    params = {
        "ref": branch
    }
    
    response = requests.get(api_url, headers=headers, params=params)
    
    if response.status_code == 200:
        # æª”æ¡ˆå­˜åœ¨ï¼Œå–å¾— sha
        sha = response.json()["sha"]
    elif response.status_code == 404:
        # æª”æ¡ˆä¸å­˜åœ¨ï¼Œsha None
        sha = None
    else:
        print(f"å–å¾—æª”æ¡ˆè³‡è¨Šå¤±æ•—ï¼Œç‹€æ…‹ç¢¼: {response.status_code}")
        print(response.text)
        return False
    
    # è®€å–æª”æ¡ˆä¸¦ base64 encode
    with open(file_path, "rb") as f:
        content = f.read()
    content_b64 = base64.b64encode(content).decode()
    
    data = {
        "message": commit_message,
        "content": content_b64,
        "branch": branch,
    }
    if sha:
        data["sha"] = sha
    
    put_resp = requests.put(api_url, headers=headers, data=json.dumps(data))
    
    if put_resp.status_code in [200, 201]:
        print(f"æˆåŠŸæ¨é€æª”æ¡ˆåˆ° GitHub: {file_path}")
        return True
    else:
        print(f"æ¨é€å¤±æ•—ï¼Œç‹€æ…‹ç¢¼: {put_resp.status_code}")
        print(put_resp.text)
        return False

def download_zip(season_code):
    base_url = "https://plvr.land.moi.gov.tw/DownloadSeason"
    params = {
        "season": season_code,
        "type": "zip",
        "fileName": "lvr_landcsv.zip"
    }
    response = requests.get(base_url, params=params, stream=True)

    if response.status_code == 200:
        os.makedirs("data", exist_ok=True)
        zip_path = f"./data/moi_data_{season_code}.zip"
        with open(zip_path, "wb") as f:
            f.write(response.content)
        print(f"âœ… å·²ä¸‹è¼‰ï¼š{zip_path}")
        return zip_path
    else:
        raise Exception(f"ä¸‹è¼‰å¤±æ•—ï¼Œç‹€æ…‹ç¢¼ï¼š{response.status_code}")

def unzip_file(zip_path, extract_to):
    os.makedirs(extract_to, exist_ok=True)
    with zipfile.ZipFile(zip_path, 'r') as zip_ref:
        zip_ref.extractall(extract_to)
    print(f"âœ… å·²è§£å£“ç¸®è‡³ï¼š{extract_to}")

def process_real_estate_data(data_folder_path):
    all_data = []
    
    land_files = glob.glob(os.path.join(data_folder_path, "*_lvr_land_*.csv"))
    
    for land_file in land_files:
        filename = os.path.basename(land_file)
        city_code = filename[0].lower()
        
        if city_code not in city_code_map:
            print(f"è­¦å‘Š: æœªçŸ¥çš„åŸå¸‚ä»£ç¢¼ {city_code} åœ¨æª”æ¡ˆ {filename}")
            continue
        
        city_name = city_code_map[city_code]
        build_file = land_file.replace('.csv', '_build.csv')
        
        if not os.path.exists(build_file):
            print(f"è­¦å‘Š: æ‰¾ä¸åˆ°å°æ‡‰çš„å»ºç‰©æª”æ¡ˆ {build_file}")
            continue
        
        try:
            print(f"è™•ç† {city_name} çš„è³‡æ–™...")
            land_df = pd.read_csv(land_file)
            build_df = pd.read_csv(build_file)
            
            land_df.columns = land_df.columns.str.strip()
            build_df.columns = build_df.columns.str.strip()
            
            serial_columns = ['ç·¨è™Ÿ', 'The serial number', 'åºè™Ÿ']
            land_serial_col = next((col for col in serial_columns if col in land_df.columns), None)
            build_serial_col = next((col for col in serial_columns if col in build_df.columns), None)
            
            if land_serial_col is None or build_serial_col is None:
                print(f"è­¦å‘Š: ç„¡æ³•æ‰¾åˆ°ç·¨è™Ÿæ¬„ä½åœ¨æª”æ¡ˆ {filename}")
                continue
            
            district_col = next((col for col in ['é„‰é®å¸‚å€', 'è¡Œæ”¿å€'] if col in land_df.columns), None)
            price_col = next((col for col in ['å–®åƒ¹å…ƒå¹³æ–¹å…¬å°º', 'å¹³æ–¹å…¬å°ºå–®åƒ¹(å…ƒ)', 'å–®åƒ¹(å…ƒ/å¹³æ–¹å…¬å°º)'] if col in land_df.columns), None)
            age_col = next((col for col in ['å±‹é½¡', 'room age', 'å»ºç‰©å®Œæˆå¹´æœˆ'] if col in build_df.columns), None)
            target_col = next((col for col in ['äº¤æ˜“æ¨™çš„'] if col in land_df.columns), None)
            zone_col = next((col for col in ['éƒ½å¸‚åœŸåœ°ä½¿ç”¨åˆ†å€'] if col in land_df.columns), None)
            
            if None in [district_col, price_col, age_col, target_col, zone_col]:
                print(f"è­¦å‘Š: å¿…è¦æ¬„ä½ç¼ºå¤±ï¼Œè·³éæª”æ¡ˆ {filename}")
                continue
            
            land_df_filtered = land_df[land_df[target_col] != 'è»Šä½']
            land_df_filtered = land_df_filtered[land_df_filtered[zone_col].str.contains('ä½', na=False)]
            
            merged_df = pd.merge(
                land_df_filtered[[land_serial_col, district_col, price_col]],
                build_df[[build_serial_col, age_col]],
                left_on=land_serial_col,
                right_on=build_serial_col,
                how='inner'
            )
            
            merged_df = merged_df.dropna(subset=[age_col])
            
            merged_df[price_col] = pd.to_numeric(merged_df[price_col], errors='coerce')
            merged_df[age_col] = pd.to_numeric(merged_df[age_col], errors='coerce')
            
            merged_df = merged_df[(merged_df[price_col] > 0) & (merged_df[price_col].notna())]
            
            merged_df['ç¸£å¸‚'] = city_name
            merged_df['BUILD'] = merged_df[age_col].apply(classify_building_age)
            
            merged_df = merged_df.rename(columns={
                district_col: 'è¡Œæ”¿å€',
                price_col: 'å–®åƒ¹å…ƒå¹³æ–¹å…¬å°º'
            })
            
            final_df = merged_df[['ç¸£å¸‚', 'è¡Œæ”¿å€', 'BUILD', 'å–®åƒ¹å…ƒå¹³æ–¹å…¬å°º']].copy()
            all_data.append(final_df)
            
        except Exception as e:
            print(f"éŒ¯èª¤: è™•ç†æª”æ¡ˆ {filename} æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            continue
    
    if not all_data:
        print("éŒ¯èª¤: æ²’æœ‰æˆåŠŸè™•ç†ä»»ä½•æª”æ¡ˆ")
        return None
    
    combined_df = pd.concat(all_data, ignore_index=True)
    combined_df = combined_df.dropna(subset=['BUILD'])
    
    result_df = combined_df.groupby(['ç¸£å¸‚', 'è¡Œæ”¿å€', 'BUILD']).agg({
        'å–®åƒ¹å…ƒå¹³æ–¹å…¬å°º': ['mean', 'count']
    }).round(2)
    
    result_df.columns = ['å¹³å‡å–®åƒ¹å…ƒå¹³æ–¹å…¬å°º', 'äº¤æ˜“ç­†æ•¸']
    result_df = result_df.reset_index()
    return result_df

def main(season_code):
    season_code_2 = convert_season_code_input(season_code)  # åŠ é€™è¡Œåšè½‰æ›

    zip_path = download_zip(season_code_2)
    extract_to = f"./data/lvr_landcsv_{season_code_2}"
    unzip_file(zip_path, extract_to)

    result = process_real_estate_data(extract_to)
    if result is not None:
        quarter_str = season_code_to_chinese_quarter(season_code_2)
        result['å­£åº¦'] = [quarter_str] * len(result)

        os.makedirs("output", exist_ok=True)
        export_season_code = convert_season_code_for_export(season_code_2)
        output_file = f"./output/åˆä½µå¾Œä¸å‹•ç”¢çµ±è¨ˆ_{export_season_code}.csv"
        result.to_csv(output_file, index=False, encoding='utf-8-sig')
        print(f"ğŸ“„ çµ±è¨ˆå®Œæˆï¼Œå·²è¼¸å‡º: {output_file}")

        repo_owner = "ericeeic"
        repo_name = "STUDENT_PROJECT"
        branch = "main"
        commit_message = f"æ›´æ–°çµ±è¨ˆè³‡æ–™ {season_code_2}"
        github_token = os.environ.get("GITHUB_TOKEN")

        if github_token:
            github_push_file(repo_owner, repo_name, branch, output_file, commit_message, github_token)
        else:
            print("âŒ æ‰¾ä¸åˆ° GITHUB_TOKENï¼Œè«‹ç¢ºèªæ˜¯å¦æœ‰è¨­å®šç’°å¢ƒè®Šæ•¸")
    else:
        print("âš ï¸ è³‡æ–™è™•ç†å¤±æ•—")

if __name__ == "__main__":
    season = input("è«‹è¼¸å…¥æ¬²ä¸‹è¼‰çš„æœŸæ•¸ï¼ˆä¾‹å¦‚ï¼š114S2ï¼‰ï¼š").strip()
    main(season)












